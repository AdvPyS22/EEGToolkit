<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>EEGToolkit.EEGData.EEGData API documentation</title>
<meta name="description" content="This module provides a data class `EEGData` to work with EEG signal data for event-reaction-time delay experiments.
It works with two separate input â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>EEGToolkit.EEGData.EEGData</code></h1>
</header>
<section id="section-intro">
<p>This module provides a data class <code><a title="EEGToolkit.EEGData.EEGData.EEGData" href="#EEGToolkit.EEGData.EEGData.EEGData">EEGData</a></code> to work with EEG signal data for event-reaction-time delay experiments.
It works with two separate input datafiles, one storing the EEG signal itself as a 1D array, and one
describing event metadata as a 2D array, describing both the timepoints and the type of event in two columns.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;

This module provides a data class `EEGData` to work with EEG signal data for event-reaction-time delay experiments.
It works with two separate input datafiles, one storing the EEG signal itself as a 1D array, and one 
describing event metadata as a 2D array, describing both the timepoints and the type of event in two columns.

&#34;&#34;&#34;
import sys
import os 

import subprocess
import inspect
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

try:
    from EEGToolkit.EEGStats import plot_signal, difference_plot
except ImportError:
    abspath = os.path.abspath(__file__)
    dname = os.path.dirname(os.path.dirname(abspath))
    sys.path.append(dname)

    from EEGStats import plot_signal, difference_plot
    

supported_filetypes = [ &#34;npy&#34;, &#34;tsv&#34;, &#34;csv&#34;, &#34;txt&#34; ]
class EEGData():
    &#34;&#34;&#34;
    Handles EEG data stored from two separate datafiles, one for the EEG signal
    and one for the corresponding events. 

    Input Datafiles
    --------------
    The EEG signal datafile must be a 1D array of values. 
    The events datafile must be a 2D array of timepoints at which an event occurs,
    as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
    datafiles must **not** contain any headers!

    Supported file types are:
    - `npy`
    - `txt`     ( space-separated for events datafiles )
    - `tsv`
    - `csv`     (both `,` and `;` separated )   

    Parameters
    ----------
    signal_path : str
        A filepath to a valid datafile containing EEG signal data.
    
    event_path : str
        A filepath to a valid datafile containing corresponding 
        event information for the signal datafile.

    sampling_frequency : float
        The frequency at which the EEG was recorded in `Hertz`.

    &#34;&#34;&#34;

    def __init__(self,
                 signal_path:str,
                 event_path:str,
                sampling_frequency:float) -&gt; None:

        # store the used datafiles...
        self._signal_src = signal_path
        self._event_src = event_path

        # first check for valid input data
        self._check_sanity(signal_path, event_path, sampling_frequency)

        # read the datafiles...
        self.read( signal_path = signal_path, event_path = event_path )    

        # now setup the frames for the events 
        self._n_frames = len(self.signal)

        # this will setup self._events which is a
        # dictionary of event identifiers : number of repeated measurements
        self._set_n_events()

        # setup a _data argument for the 
        # extracted event datasets
        self._data = None 

        # store the frequency
        self.sampling_frequency = sampling_frequency
        
        # setup default parameters for the window around
        # which each event signal should be extracted
        # in seconds
        self._start_sec = -0.5
        self._stop_sec = 1

        # and setup the extracted events in case 
        # only a subset are being extacted
        self._extracted_events = None

        # save a baseline for each event type which will be an 
        # np.ndarray to store the timepoints (or a subset thereof)
        # before the signal onset. The time points will be sampled
        # from the extracted timepoints...
        self._baseline = None

        # setup a dictionary to store the p-values of pair-wise comparison
        # between either two signals or a signal with it&#39;s baseline.
        # keys will be tuples of signal1, signal2, for baseline comparison
        # signal1 = signal2...
        self._pvalues = {}

    def read( self, signal_path : str = None , event_path : str = None ) -&gt; None: 
        &#34;&#34;&#34;
        Read the provided data files and stores the
        data into numpy ndarrays.

        Note
        ----
        This method is automatically called at initiation. However, new data
        can be loaded using this method manually.

        Input Datafiles
        --------------
        The EEG signal datafile must be a 1D array of values. 
        The events datafile must be a 2D array of timepoints at which an event occurs,
        as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
        datafiles must **not** contain any headers!

        Supported file types are:
        - `npy`
        - `txt`     ( space-separated for events datafiles )
        - `tsv`
        - `csv`     (both `,` and `;` separated )   

        Parameters
        ----------
        signal_path : str
            A filepath to a valid datafile containing EEG signal data.
        
        event_path : str
            A filepath to a valid datafile containing corresponding 
            event information for the signal datafile.

        &#34;&#34;&#34;
        
        # first read the signal data file
        if signal_path is not None:
            suffix = self._filesuffix( signal_path )
            if suffix == &#34;npy&#34;: 
                signal = self._read_npy( signal_path )
            else: 
                signal = self._read_datafile( signal_path )

            # now save
            self.signal = signal

        # now the same for the events data file 
        if event_path is not None: 
            suffix = self._filesuffix( event_path )
            if suffix == &#34;npy&#34;: 
                events = self._read_npy( event_path )
            else: 
                events = self._read_datafile( event_path )

            # now save
            self._events_data = events

    def extract(self,
                start_sec:float,
                stop_sec:float,
                event_type : ( int or tuple or list or np.ndarray ) = None, 
                **kwargs ) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Extracts data for a specific (set of) event(s) from the loaded data. 
        And returns the data as numpy ndarrays (or a list thereof, in case of 
        multiple events).

        Note
        ----
        This method is automatically called by `EGGData.summary` so it is not necessary
        to manually extract data, unless only a specific subset of event types should
        be extracted!

        Parameters
        ----------
        start_sec : float
            The timepoint relative to the provided 
            events data in seconds at which to begin extraction. 
            E.g. `-0.05` would correspond to `0.05 seconds` before
            the actual onset of the recorded event.

        stop_sec : float
            The timepoint relative to the provided 
            events data in seconds at which to end extraction. 
            E.g. `0.75` would correspond to `0.75 seconds` after
            the actual onset of the recorded event.
        
        event_type : int or tuple or list or np.ndarray
            Either a single event type or an iterable of multiple event types.
            If `event_type = None` (default) data for **all** event types will be extracted!

        Returns
        -------
        extracted_data : np.ndarray or list
            The data of the provided events as an ndarray or a 
            list of ndarrays in the same order as the provided event-type labels.
        &#34;&#34;&#34;

        # check if we should extract the data for all events
        if event_type is None:

            # get all events
            events_to_extract = self._events.keys()

            # extract each type from the loaded data
            data = [ 
                        self.extract(start_sec, stop_sec, etype) 
                        for etype in events_to_extract 
                ]

            self._data = data
            self._extracted_events = events_to_extract
            return data

        # check if there is a provided subset of events to extract
        if isinstance(event_type, (tuple, np.ndarray, list)):

            events_to_extract = event_type

            # extract provided type from the loaded data
            data = [ 
                        self.extract(start_sec, stop_sec, etype) 
                        for etype in events_to_extract 
                ]

            self._data = data
            self._extracted_events = events_to_extract
            return data

        # now the part for extracting only a 
        # single event type data
        data = self._extract_window(start_sec, stop_sec, event_type)
        self._data = data

        self._extracted_events = event_type

        # store start and stop sec values
        # for later use in summary()
        self._start_sec = start_sec
        self._stop_sec = stop_sec

        return data

    def baseline( self, size : int or float = None ):
        &#34;&#34;&#34;
        Generates a baseline distribution for EEG Signals,
        using random sampling from pre-signal timepoints accross 
        replicates and events.

        Note
        ----
        This requires that events have already been extacted!

        Parameters
        ----------
        size : int or float
            The number of random samples to draw. If `None` are provided (default)
            the entire available pre-signal data is used. If an `integer` is provided
            then the final baseline data contains exactly the given number of datapoints.
            Alternatively, a `float` `0 &lt; size &lt;= 1` may be provided to specify a fraction
            of data to sample from. E.g. `size = 0.2` would incorporate 20% of the available
            datapoints into the baseline.
        
        Returns
        -------
        baseline : np.ndarray
            An np.ndarray of the randomly drawn samples.
        &#34;&#34;&#34;
        start_sec, stop_sec = self._start_sec, self._stop_sec

        # first get the time period before t=0, beginning at the starting time...
        if isinstance( self._data, list ):
            random_samples = [ self._extract_window( start_sec, 0, e ) for e in self._extracted_events ]
        elif isinstance( self._data, np.ndarray ):
            random_samples = [ self._extract_window( start_sec, 0, self._extracted_events ) ]        
        elif self._data is None:
            raise Exception( f&#34;No events data has been extracted yet! Make sure to run extract() before computing a baseline.&#34; )

        # collapse the repeats into a single dataset
        random_samples = [ np.reshape( i, i.size ) for i in random_samples ] 

        # now if there is a provided size we subsample
        if size is not None: 
            if size &lt;= 1:
                random_samples = [ np.random.choice( i, size = size * i.size ) for i in random_samples ]
            elif size &gt; 1:
                random_samples = [ np.random.choice( i, size = size ) for i in random_samples ]
            else:
                raise ValueError( f&#34;size needs to be a fraction in [0,1] or an integer &gt; 1 (got size = {size})&#34; )

        self._baseline = random_samples

        # Alright, we currently have the entire sets of pre-timeframes for the baseline and we
        # will use them as they are completely to use for the baseline comparison. 
        # With the code below we compare a sub-sampled versions thereof. Long story short,
        # it works also pretty well with sub-sampled versions as well...
        # import statsmodels.api as sm
        # from matplotlib import colors

        # fig, ax = plt.subplots( 2,3 ) 
        # for r in random_samples:
        #     ax[0,0].plot( r )
        #     r1 = r.reshape( r.size )
        #     ax[0,1].hist( r1, bins = 50 )

        #     sm.qqplot( r1, ax = ax[0,2], alpha = 0.3, line = &#34;s&#34;, color = list(colors.cnames.values())[ int(np.random.randint(low = 0, high = 10, size = 1))]  )
        # random_samples = [ np.random.choice( r.reshape(r.size), size = size, replace = False ) for r in random_samples ]
        
        # for r in random_samples:
        #     ax[1,0].plot( r )
        #     r1 = np.reshape( r, r.size )
        #     ax[1,1].hist( r1, bins = 50 )
            
        #     sm.qqplot( r1, ax = ax[1,2], alpha = 0.3, line = &#34;s&#34;, color =  list(colors.cnames.values())[ int(np.random.randint(low = 0, high = 10, size = 1))] )
        # # ax[1].hist( np.reshape( random_samples, random_samples.size)  )
        # plt.tight_layout()
        # plt.show()


    def pvalues( self, event1 : int, event2 : int = None ):
        &#34;&#34;&#34;
        Gets the p-value np.ndarray for each signal timepoint from a comparison of 
        either two separate event types or one event with its baseline. 

        Parameters
        ----------
        event1 : int
            The numeric event identifier of the (first) signal to get.
            If `None` is provided, the entire dictionary of pvalues is returned.

        event2 : int
            The numeric event identifier of the (second) signal from the comparison to get.
            If `None` is provided then the first signals comparison to it&#39;s baseline will be 
            returned (if baseline comparison was performed).
        
        Returns
        -------
        pvalues : np.ndarray or dict
            An np.ndarray of p-values from a given comparison.
        &#34;&#34;&#34;

        if event1 is None: 
            return self._pvalues

        if event2 is None:
            key = (event1, event1)
        else: 
            key = (event1, event2)
        pvalues = self._pvalues.get( key, None )
        return pvalues 

    @property
    def events( self ):
        &#34;&#34;&#34;
        Returns 
        -------
        list
            A list of all different event types from from the loaded metadata.
        &#34;&#34;&#34;
        return list( self._events.keys() )

    @property
    def timeframe( self ):
        &#34;&#34;&#34;
        Returns
        -------
        tuple   
            The used timeframe for event data extraction.
            This consists of the pre-trigger and post-trigger
            time offsets in seconds.
        &#34;&#34;&#34;
        return ( self._start_sec, self._stop_sec )



    def summary(self,
                x_scale:float,
                y_scale:float,
                significance_level:float = 0.05,
                output:str = None,
                **kwargs ) -&gt; None:
        &#34;&#34;&#34;
        Performs pair-wise T-Tests to compare extracted event data 
        (automatically extracts data for all events if no events were extracted yet). 
        Results are summarised in a figure. Individual signals are plotted
        on the diagonal by their mean signal accross replicates with indicated SEM.
        On non-diagonal plots pair-wise comparisons between two signals (one &#34;horizontal&#34;
        and one &#34;vertical&#34; ) are shown. Regions of significant differences are shaded.

        Parameters
        ----------

        x_scale : float
            A scaling factor to adjust the data&#39;s x-value range. 
            E.g. `x_scale = 1000` to adjust the time-scale to milliseconds.
        
        y_scale : float
            A scaling factor for the data&#39;s y-value range.
            E.g. `y_scale = 1000` to adjust the signal-scale to millivolts.

        significance_level : float
            The threshold for accepting a signal difference as significant.
            Default is `0.05`.
        
        output : str
            The output filename to save the summary figure into.

        **kwargs
            Any additional keyword arguments to pass to `EEGData.extract` in case
            no event data has been extracted yet.
        &#34;&#34;&#34;

        # extract the event data if not yet done already
        start_sec = kwargs.pop( &#34;start_sec&#34;, self._start_sec )
        stop_sec = kwargs.pop( &#34;stop_sec&#34;, self._stop_sec )
        if self._data is None: 

            self.extract( start_sec = start_sec, stop_sec = stop_sec, **kwargs )
            self.baseline() 

        data = list( self._data ) 
        signals = list(self._events.keys())
        n = len(data)

        # generate a new figure
        figsize = kwargs.pop( &#34;figsize&#34;, ( 3*n,2*n ) )
        fig, ax = plt.subplots(n,n, figsize = figsize )

        # setup a baseline reference, either with the computed
        # baselines or None ...
        baseline = self._baseline if self._baseline is not None else [ None for i in range(n) ]
    
        # now first plot the individual signals
        # on their own on diagonal plots
        for i in range(n):

            # only the last subplot should make a legend
            make_legend = i == n-1 
            p = plot_signal(
                    data[i], 
                    self.sampling_frequency, 
                    start_sec, stop_sec, 
                    x_scale, y_scale,
                    baseline = baseline[i],
                    make_legend = make_legend,
                    significance_level = significance_level,
                    ax = ax[i,i] )
                
            ax[i,i].set_title(f&#34;Signal {signals[i]}&#34;)

            # if we got a baseline to compare to we also want to 
            # store the resulting p-values
            if p is not None: 
                self._pvalues[ (i,i) ] = p 

            # hide all &#34;left-over&#34; subplots from the layout
            # i.e. hide the upper-right half of the figure...
            for a in ax[ i, i+1: ]:
                a.axis(&#34;off&#34;)

        # now make pair-wise comparisons between two signals
        # plotting the results on the lower-left half of the 
        # figure...
        for i,j in [(i,j) for i in range(n) for j in range(i)]:

            # only the last plot shall make a legend
            make_legend = i == n-1 and j == i-1 

            p = difference_plot( 
                                data[i], 
                                data[j], 
                                self.sampling_frequency, 
                                start_sec, stop_sec, 
                                significance_level, 
                                x_scale, y_scale,
                                make_legend = make_legend,
                                ax = ax[i,j]
                            )
            ax[i,j].set_title(f&#34;Signals: {signals[j]} vs {signals[i]}&#34;)

            # we also want to store the resulting p-values of the 
            # signal comparison
            self._pvalues[ ( signals[j],signals[i] ) ] = p

        fig.tight_layout()
        
        if output is None:
            plt.show()
            return fig
        plt.savefig(output, bbox_inches = &#34;tight&#34; )


    def _extract_window(self, start_sec, stop_sec, event_type):
        &#34;&#34;&#34;
        Extracts a set of time-frame windows from the data 
        and returns them as a numpy ndarray.
        &#34;&#34;&#34;

        # first adjust the start and end to 
        # match the sampling frequency
        start_frame, stop_frame = self._adjust_timesteps(start_sec, stop_sec)

        # next generate a set of slices for the EEG data around the timepoints for
        # the events
        firing_slices = [
                            slice( event[0]+start_frame, event[0]+stop_frame ) 
                            for event in self._events_data 
                            if event[1] == event_type
                    ]

        # now get the actual data of the event
        data = [ self.signal[ slice ] for slice in firing_slices ]
        data = np.array( data )
        return data

    def _adjust_timesteps(self, start_sec, stop_sec):
        &#34;&#34;&#34;
        Adjusts time steps / time points with the used recording frequency,
        to match the indices within the data.
        &#34;&#34;&#34;
        start_frame = int( start_sec * self.sampling_frequency )
        stop_frame = int( stop_sec * self.sampling_frequency )
        return start_frame,stop_frame

    def _set_n_events(self) -&gt; None:
        &#34;&#34;&#34;
        Sets up a dictionary of the different event types
        found in the events data.
        &#34;&#34;&#34;

        event_types = {event[1] for event in self._events_data}
        self._events = {event_type: len([event for event in self._events_data if event[1] == event_type]) for event_type in event_types}            

    def _check_sanity(self, signal_path, event_path, sampling_frequency):
        &#34;&#34;&#34;
        Checks if valid data inputs were provided
        &#34;&#34;&#34;

        # check if input files exist
        if not os.path.isfile(signal_path):
            raise FileNotFoundError( f&#34;The signal datafile could not be found at &#39;{signal_path}&#39;!&#34; )
        
        if not os.path.isfile(event_path):
            raise FileNotFoundError( f&#34;The event datafile could not be found at &#39;{event_path}!&#34; )
        
        # check if the datafiles conform to suppored filetypes
        fname = os.path.basename(signal_path)
        if not any( [ fname.endswith(suffix) for suffix in supported_filetypes ] ):
            suffix = fname.split(&#34;.&#34;)[-1]
            raise TypeError( f&#34;The signal datafile could not be interpreted (&#39;.{suffix}&#39;), only {supported_filetypes} files are supported!&#34; )

        fname = os.path.basename(event_path)
        if not any( [ fname.endswith(suffix) for suffix in supported_filetypes ] ):
            suffix = fname.split(&#34;.&#34;)[-1]
            raise TypeError( f&#34;The event datafile could not be interpreted (&#39;.{suffix}&#39;), only {supported_filetypes} files are supported!&#34; )
        
        # check if the frequency is a positive number
        if not sampling_frequency &gt; 0:
            raise ValueError( f&#34;Sampling frequency {sampling_frequency} must be a positive value&#34; )

    def _read_npy( self, filepath ) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Reads data from npy files
        &#34;&#34;&#34;
        data = np.load(filepath)
        return data 

    def _read_datafile( self, filepath) -&gt; np.ndarray: 
        &#34;&#34;&#34;
        Reads data from tsv, csv, and txt files
        &#34;&#34;&#34;

        # first get the filetype 
        suffix = self._filesuffix(filepath)

        # now get the corresponding delimiter
        delimiters = {
                        &#34;csv&#34; : self._csv_delimiter( filepath ),
                        &#34;tsv&#34; : &#34;\t&#34;,
                        &#34;txt&#34; : &#34; &#34;
                    }
        delimiter = delimiters[ suffix ]
        
        # now read the file
        data = pd.read_csv( filepath, header = None, sep = delimiter )

        # convert to numpy ndarray
        data = data.to_numpy()
        data = np.squeeze( data )
        return data 

    def _filesuffix(self, filepath):
        &#34;&#34;&#34;
        Returns the suffix from a filepath
        &#34;&#34;&#34;
        suffix = os.path.basename( filepath )
        suffix = suffix.split(&#34;.&#34;)[-1]
        return suffix

    def _csv_delimiter(self, filepath):
        &#34;&#34;&#34;
        Checks if a csv file is , or ; delimited and returns the 
        correct delmiter to use...
        &#34;&#34;&#34;
        # open the file and read 
        with open( filepath, &#34;r&#34; ) as f:
            content = f.read()

        # check if a semicolon is present
        # if so, we delimit at ; 
        has_semicolon = &#34;;&#34; in content
        delimiter = &#34;;&#34; if has_semicolon else &#34;,&#34;

        return delimiter

def main():
    &#34;&#34;&#34;
    The main function called through the CLI

    Example Usage
    -------------
    python3 ./EEGToolkit/EEGData.py \
        --eeg_path &#34;data/eeg.npy&#34; \
        --event_path &#34;data/events.npy&#34; \
        --sampling_frequency 500 \
        --p_value 0.05 \
        --start_sec -0.3 \
        --stop_sec 1.0 \
        --x_scale 1000 \
        --y_scale 1000 \
        --output &#34;./test.png&#34;
    &#34;&#34;&#34;

    descr1 = &#34;&#34;&#34;

-----------------------------------------------------
â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–€â–€â–ˆ â–€â–€â–ˆâ–€â–€ â–ˆâ–€â–€â–ˆ â–ˆâ–€â–€â–ˆ â–ˆâ–‘â–‘ â–’â–ˆâ–‘â–„â–€ â–‘â–€â–‘ â–€â–€â–ˆâ–€â–€
â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–‘â–„â–„ â–‘â–’â–ˆâ–‘â–‘ â–ˆâ–‘â–‘â–ˆ â–ˆâ–‘â–‘â–ˆ â–ˆâ–‘â–‘ â–’â–ˆâ–€â–„â–‘ â–€â–ˆâ–€ â–‘â–‘â–ˆâ–‘â–‘
â–’â–ˆâ–„â–„â–„ â–’â–ˆâ–„â–„â–„ â–’â–ˆâ–„â–„â–ˆ â–‘â–’â–ˆâ–‘â–‘ â–€â–€â–€â–€ â–€â–€â–€â–€ â–€â–€â–€ â–’â–ˆâ–‘â–’â–ˆ â–€â–€â–€ â–‘â–‘â–€â–‘â–‘
-----------------------------------------------------

This script takes in two data files of EEG signal data and accompanying event-trigger metadata. It performs intra- and inter-signal type comparisons using pair-wise T-Tests over the time-series, highlighting significantly different stretches and producing a summary figure. 
    &#34;&#34;&#34;
    descr2 = f&#34;&#34;&#34;

Input Data
----------
Accepted input file types are {supported_filetypes}. The EEG-signal datafile must specify a 1D array of measurements, while the trigger metadata file must specify a 2D array (2 columns) of trigger time points and event classifier labels (numerically encoded). 
    &#34;&#34;&#34;
    
    parser = argparse.ArgumentParser( prefix_chars = &#34;-&#34;, 
    formatter_class=argparse.RawDescriptionHelpFormatter,description = descr1, epilog = descr2 )
    parser.add_argument(
                            &#34;--eeg_path&#34;, &#34;--eeg&#34;, 
                            type=str,
                            help = f&#34;A file containing EEG signal data. Supported filetypes are {supported_filetypes}&#34; 
                    )
    parser.add_argument(
                            &#34;--event_path&#34;, &#34;--event&#34;, 
                            type=str,
                            help = f&#34;A file containing event metadata for the signal file. Supported filetypes are {supported_filetypes}&#34;
                    )
    parser.add_argument(
                            &#34;--output&#34;, &#34;-o&#34;, 
                            type=str, default = None,
                            help = &#34;An output file into which the output summary figure should be saved. If none is provided (default) the Figure will simply be shown.&#34;
                    )
    parser.add_argument(
                            &#34;--sampling_frequency&#34;, &#34;--freq&#34;, &#34;-f&#34;, 
                            type=float,
                            help = &#34;The frequency at which the EEG signal data was recorded (in Hertz).&#34;
                    )
    parser.add_argument(
                            &#34;--p_value&#34;, &#34;-p&#34;, 
                            type=float, default = 0.05, 
                            help = &#34;The significance threshold at which to accept two signals being significantly different at a T-Test comparison. Default is 0.05.&#34;
                    )
    parser.add_argument(
                            &#34;--start_sec&#34;, &#34;--start&#34;, &#34;-s&#34;, 
                            type=float,
                            help = &#34;The upstream time-padding for event extraction (in seconds).&#34;
                    )
    parser.add_argument(
                            &#34;--stop_sec&#34;, &#34;--stop&#34;, &#34;-e&#34;, 
                            type=float,
                            help = &#34;The downstream time-padding for event extraction (in seconds).&#34;
                    )
    
    parser.add_argument(
                            &#34;--baseline&#34;, &#34;-b&#34;, 
                            type=bool, default = True,
                            help = &#34;Perform baseline comparison for each event type using the same significance threshold as used for inter-signal comparisons. Will be performed by default.&#34;
                    )
    parser.add_argument(
                            &#34;--x_scale&#34;, &#34;-x&#34;, 
                            type=float, default = 1000,
                            help = &#34;A scaling factor for the time-scale (x-values) from seconds to some other unit. Default is 1000 (= milliseconds).&#34;
                    )
    parser.add_argument(
                            &#34;--y_scale&#34;, &#34;-y&#34;, 
                            type=float, default = 1000,
                            help = &#34;A scaling factor for the signal-scale (y-values) from volts to some other unit. Default is 1000 (= millivolts).&#34;
                    )
    
    parser.add_argument(
                            &#34;--viewer&#34;, &#34;-i&#34;, 
                            action=&#34;store_true&#34;,
                            default = False,
                            help = &#34;Open the EEGToolKit Viewer GUI in a web browser.&#34;
                    )

    args = parser.parse_args()
    
    # if the viewer is being called then we want to just open the 
    # viewer and nothing else
    if args.viewer:
        # first we need to get the relative location of the main.
        # py file within the package. 
        directory = os.path.dirname( 
                                            inspect.getfile( plot_signal ) 
                                        )
        directory = os.path.dirname( directory )
        main_file = f&#34;{directory}/__main__.py&#34;

        # then we call the web interface
        print( &#34;Starting the \033[94mEEGToolKit \033[96mViewer&#34; )
        subprocess.run( f&#34;streamlit run {main_file}&#34;, shell = True )
    
    else: 

        # the main program (reading datafiles, extracting, and summarizing)
        try:
            data = EEGData(args.eeg_path, args.event_path, args.sampling_frequency)
            data.extract( args.start_sec, args.stop_sec )
            if args.baseline:
                data.baseline()
            data.summary(
                            significance_level = args.p_value,
                            x_scale = args.x_scale,
                            y_scale = args.y_scale,
                            output = args.output
                        )

            if args.output is not None: 
                print( f&#34;Output saved successfully to: &#39;{args.output}&#39;&#34; )
        except FileNotFoundError as e:
            print(e)
            return
        except TypeError as e:
            print(e)
            return
        except ValueError as e:
            print(e)
            return

if __name__ == &#34;__main__&#34;:

    test_mode = False
    if not test_mode:
        main()
    else: 
        print( &#34;Running in Test Mode&#34; )

        eeg = &#34;./data/eeg.npy&#34;
        events = &#34;./data/events.npy&#34;

        e = EEGData( eeg, events, 500 )
        e.extract( -0.3, 1 )
        e.baseline()
        e.summary( 1000, 1000, output = &#34;./test.pdf&#34; )
        plt.show()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="EEGToolkit.EEGData.EEGData.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>The main function called through the CLI</p>
<h2 id="example-usage">Example Usage</h2>
<p>python3 ./EEGToolkit/EEGData.py
&ndash;eeg_path "data/eeg.npy"
&ndash;event_path "data/events.npy"
&ndash;sampling_frequency 500
&ndash;p_value 0.05
&ndash;start_sec -0.3
&ndash;stop_sec 1.0
&ndash;x_scale 1000
&ndash;y_scale 1000
&ndash;output "./test.png"</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    &#34;&#34;&#34;
    The main function called through the CLI

    Example Usage
    -------------
    python3 ./EEGToolkit/EEGData.py \
        --eeg_path &#34;data/eeg.npy&#34; \
        --event_path &#34;data/events.npy&#34; \
        --sampling_frequency 500 \
        --p_value 0.05 \
        --start_sec -0.3 \
        --stop_sec 1.0 \
        --x_scale 1000 \
        --y_scale 1000 \
        --output &#34;./test.png&#34;
    &#34;&#34;&#34;

    descr1 = &#34;&#34;&#34;

-----------------------------------------------------
â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–€â–€â–ˆ â–€â–€â–ˆâ–€â–€ â–ˆâ–€â–€â–ˆ â–ˆâ–€â–€â–ˆ â–ˆâ–‘â–‘ â–’â–ˆâ–‘â–„â–€ â–‘â–€â–‘ â–€â–€â–ˆâ–€â–€
â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–€â–€â–€ â–’â–ˆâ–‘â–„â–„ â–‘â–’â–ˆâ–‘â–‘ â–ˆâ–‘â–‘â–ˆ â–ˆâ–‘â–‘â–ˆ â–ˆâ–‘â–‘ â–’â–ˆâ–€â–„â–‘ â–€â–ˆâ–€ â–‘â–‘â–ˆâ–‘â–‘
â–’â–ˆâ–„â–„â–„ â–’â–ˆâ–„â–„â–„ â–’â–ˆâ–„â–„â–ˆ â–‘â–’â–ˆâ–‘â–‘ â–€â–€â–€â–€ â–€â–€â–€â–€ â–€â–€â–€ â–’â–ˆâ–‘â–’â–ˆ â–€â–€â–€ â–‘â–‘â–€â–‘â–‘
-----------------------------------------------------

This script takes in two data files of EEG signal data and accompanying event-trigger metadata. It performs intra- and inter-signal type comparisons using pair-wise T-Tests over the time-series, highlighting significantly different stretches and producing a summary figure. 
    &#34;&#34;&#34;
    descr2 = f&#34;&#34;&#34;

Input Data
----------
Accepted input file types are {supported_filetypes}. The EEG-signal datafile must specify a 1D array of measurements, while the trigger metadata file must specify a 2D array (2 columns) of trigger time points and event classifier labels (numerically encoded). 
    &#34;&#34;&#34;
    
    parser = argparse.ArgumentParser( prefix_chars = &#34;-&#34;, 
    formatter_class=argparse.RawDescriptionHelpFormatter,description = descr1, epilog = descr2 )
    parser.add_argument(
                            &#34;--eeg_path&#34;, &#34;--eeg&#34;, 
                            type=str,
                            help = f&#34;A file containing EEG signal data. Supported filetypes are {supported_filetypes}&#34; 
                    )
    parser.add_argument(
                            &#34;--event_path&#34;, &#34;--event&#34;, 
                            type=str,
                            help = f&#34;A file containing event metadata for the signal file. Supported filetypes are {supported_filetypes}&#34;
                    )
    parser.add_argument(
                            &#34;--output&#34;, &#34;-o&#34;, 
                            type=str, default = None,
                            help = &#34;An output file into which the output summary figure should be saved. If none is provided (default) the Figure will simply be shown.&#34;
                    )
    parser.add_argument(
                            &#34;--sampling_frequency&#34;, &#34;--freq&#34;, &#34;-f&#34;, 
                            type=float,
                            help = &#34;The frequency at which the EEG signal data was recorded (in Hertz).&#34;
                    )
    parser.add_argument(
                            &#34;--p_value&#34;, &#34;-p&#34;, 
                            type=float, default = 0.05, 
                            help = &#34;The significance threshold at which to accept two signals being significantly different at a T-Test comparison. Default is 0.05.&#34;
                    )
    parser.add_argument(
                            &#34;--start_sec&#34;, &#34;--start&#34;, &#34;-s&#34;, 
                            type=float,
                            help = &#34;The upstream time-padding for event extraction (in seconds).&#34;
                    )
    parser.add_argument(
                            &#34;--stop_sec&#34;, &#34;--stop&#34;, &#34;-e&#34;, 
                            type=float,
                            help = &#34;The downstream time-padding for event extraction (in seconds).&#34;
                    )
    
    parser.add_argument(
                            &#34;--baseline&#34;, &#34;-b&#34;, 
                            type=bool, default = True,
                            help = &#34;Perform baseline comparison for each event type using the same significance threshold as used for inter-signal comparisons. Will be performed by default.&#34;
                    )
    parser.add_argument(
                            &#34;--x_scale&#34;, &#34;-x&#34;, 
                            type=float, default = 1000,
                            help = &#34;A scaling factor for the time-scale (x-values) from seconds to some other unit. Default is 1000 (= milliseconds).&#34;
                    )
    parser.add_argument(
                            &#34;--y_scale&#34;, &#34;-y&#34;, 
                            type=float, default = 1000,
                            help = &#34;A scaling factor for the signal-scale (y-values) from volts to some other unit. Default is 1000 (= millivolts).&#34;
                    )
    
    parser.add_argument(
                            &#34;--viewer&#34;, &#34;-i&#34;, 
                            action=&#34;store_true&#34;,
                            default = False,
                            help = &#34;Open the EEGToolKit Viewer GUI in a web browser.&#34;
                    )

    args = parser.parse_args()
    
    # if the viewer is being called then we want to just open the 
    # viewer and nothing else
    if args.viewer:
        # first we need to get the relative location of the main.
        # py file within the package. 
        directory = os.path.dirname( 
                                            inspect.getfile( plot_signal ) 
                                        )
        directory = os.path.dirname( directory )
        main_file = f&#34;{directory}/__main__.py&#34;

        # then we call the web interface
        print( &#34;Starting the \033[94mEEGToolKit \033[96mViewer&#34; )
        subprocess.run( f&#34;streamlit run {main_file}&#34;, shell = True )
    
    else: 

        # the main program (reading datafiles, extracting, and summarizing)
        try:
            data = EEGData(args.eeg_path, args.event_path, args.sampling_frequency)
            data.extract( args.start_sec, args.stop_sec )
            if args.baseline:
                data.baseline()
            data.summary(
                            significance_level = args.p_value,
                            x_scale = args.x_scale,
                            y_scale = args.y_scale,
                            output = args.output
                        )

            if args.output is not None: 
                print( f&#34;Output saved successfully to: &#39;{args.output}&#39;&#34; )
        except FileNotFoundError as e:
            print(e)
            return
        except TypeError as e:
            print(e)
            return
        except ValueError as e:
            print(e)
            return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="EEGToolkit.EEGData.EEGData.EEGData"><code class="flex name class">
<span>class <span class="ident">EEGData</span></span>
<span>(</span><span>signal_path:Â str, event_path:Â str, sampling_frequency:Â float)</span>
</code></dt>
<dd>
<div class="desc"><p>Handles EEG data stored from two separate datafiles, one for the EEG signal
and one for the corresponding events. </p>
<h2 id="input-datafiles">Input Datafiles</h2>
<p>The EEG signal datafile must be a 1D array of values.
The events datafile must be a 2D array of timepoints at which an event occurs,
as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
datafiles must <strong>not</strong> contain any headers!</p>
<p>Supported file types are:
- <code>npy</code>
- <code>txt</code>
( space-separated for events datafiles )
- <code>tsv</code>
- <code>csv</code>
(both <code>,</code> and <code>;</code> separated )
</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>signal_path</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a valid datafile containing EEG signal data.</dd>
<dt><strong><code>event_path</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a valid datafile containing corresponding
event information for the signal datafile.</dd>
<dt><strong><code>sampling_frequency</code></strong> :&ensp;<code>float</code></dt>
<dd>The frequency at which the EEG was recorded in <code>Hertz</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EEGData():
    &#34;&#34;&#34;
    Handles EEG data stored from two separate datafiles, one for the EEG signal
    and one for the corresponding events. 

    Input Datafiles
    --------------
    The EEG signal datafile must be a 1D array of values. 
    The events datafile must be a 2D array of timepoints at which an event occurs,
    as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
    datafiles must **not** contain any headers!

    Supported file types are:
    - `npy`
    - `txt`     ( space-separated for events datafiles )
    - `tsv`
    - `csv`     (both `,` and `;` separated )   

    Parameters
    ----------
    signal_path : str
        A filepath to a valid datafile containing EEG signal data.
    
    event_path : str
        A filepath to a valid datafile containing corresponding 
        event information for the signal datafile.

    sampling_frequency : float
        The frequency at which the EEG was recorded in `Hertz`.

    &#34;&#34;&#34;

    def __init__(self,
                 signal_path:str,
                 event_path:str,
                sampling_frequency:float) -&gt; None:

        # store the used datafiles...
        self._signal_src = signal_path
        self._event_src = event_path

        # first check for valid input data
        self._check_sanity(signal_path, event_path, sampling_frequency)

        # read the datafiles...
        self.read( signal_path = signal_path, event_path = event_path )    

        # now setup the frames for the events 
        self._n_frames = len(self.signal)

        # this will setup self._events which is a
        # dictionary of event identifiers : number of repeated measurements
        self._set_n_events()

        # setup a _data argument for the 
        # extracted event datasets
        self._data = None 

        # store the frequency
        self.sampling_frequency = sampling_frequency
        
        # setup default parameters for the window around
        # which each event signal should be extracted
        # in seconds
        self._start_sec = -0.5
        self._stop_sec = 1

        # and setup the extracted events in case 
        # only a subset are being extacted
        self._extracted_events = None

        # save a baseline for each event type which will be an 
        # np.ndarray to store the timepoints (or a subset thereof)
        # before the signal onset. The time points will be sampled
        # from the extracted timepoints...
        self._baseline = None

        # setup a dictionary to store the p-values of pair-wise comparison
        # between either two signals or a signal with it&#39;s baseline.
        # keys will be tuples of signal1, signal2, for baseline comparison
        # signal1 = signal2...
        self._pvalues = {}

    def read( self, signal_path : str = None , event_path : str = None ) -&gt; None: 
        &#34;&#34;&#34;
        Read the provided data files and stores the
        data into numpy ndarrays.

        Note
        ----
        This method is automatically called at initiation. However, new data
        can be loaded using this method manually.

        Input Datafiles
        --------------
        The EEG signal datafile must be a 1D array of values. 
        The events datafile must be a 2D array of timepoints at which an event occurs,
        as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
        datafiles must **not** contain any headers!

        Supported file types are:
        - `npy`
        - `txt`     ( space-separated for events datafiles )
        - `tsv`
        - `csv`     (both `,` and `;` separated )   

        Parameters
        ----------
        signal_path : str
            A filepath to a valid datafile containing EEG signal data.
        
        event_path : str
            A filepath to a valid datafile containing corresponding 
            event information for the signal datafile.

        &#34;&#34;&#34;
        
        # first read the signal data file
        if signal_path is not None:
            suffix = self._filesuffix( signal_path )
            if suffix == &#34;npy&#34;: 
                signal = self._read_npy( signal_path )
            else: 
                signal = self._read_datafile( signal_path )

            # now save
            self.signal = signal

        # now the same for the events data file 
        if event_path is not None: 
            suffix = self._filesuffix( event_path )
            if suffix == &#34;npy&#34;: 
                events = self._read_npy( event_path )
            else: 
                events = self._read_datafile( event_path )

            # now save
            self._events_data = events

    def extract(self,
                start_sec:float,
                stop_sec:float,
                event_type : ( int or tuple or list or np.ndarray ) = None, 
                **kwargs ) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Extracts data for a specific (set of) event(s) from the loaded data. 
        And returns the data as numpy ndarrays (or a list thereof, in case of 
        multiple events).

        Note
        ----
        This method is automatically called by `EGGData.summary` so it is not necessary
        to manually extract data, unless only a specific subset of event types should
        be extracted!

        Parameters
        ----------
        start_sec : float
            The timepoint relative to the provided 
            events data in seconds at which to begin extraction. 
            E.g. `-0.05` would correspond to `0.05 seconds` before
            the actual onset of the recorded event.

        stop_sec : float
            The timepoint relative to the provided 
            events data in seconds at which to end extraction. 
            E.g. `0.75` would correspond to `0.75 seconds` after
            the actual onset of the recorded event.
        
        event_type : int or tuple or list or np.ndarray
            Either a single event type or an iterable of multiple event types.
            If `event_type = None` (default) data for **all** event types will be extracted!

        Returns
        -------
        extracted_data : np.ndarray or list
            The data of the provided events as an ndarray or a 
            list of ndarrays in the same order as the provided event-type labels.
        &#34;&#34;&#34;

        # check if we should extract the data for all events
        if event_type is None:

            # get all events
            events_to_extract = self._events.keys()

            # extract each type from the loaded data
            data = [ 
                        self.extract(start_sec, stop_sec, etype) 
                        for etype in events_to_extract 
                ]

            self._data = data
            self._extracted_events = events_to_extract
            return data

        # check if there is a provided subset of events to extract
        if isinstance(event_type, (tuple, np.ndarray, list)):

            events_to_extract = event_type

            # extract provided type from the loaded data
            data = [ 
                        self.extract(start_sec, stop_sec, etype) 
                        for etype in events_to_extract 
                ]

            self._data = data
            self._extracted_events = events_to_extract
            return data

        # now the part for extracting only a 
        # single event type data
        data = self._extract_window(start_sec, stop_sec, event_type)
        self._data = data

        self._extracted_events = event_type

        # store start and stop sec values
        # for later use in summary()
        self._start_sec = start_sec
        self._stop_sec = stop_sec

        return data

    def baseline( self, size : int or float = None ):
        &#34;&#34;&#34;
        Generates a baseline distribution for EEG Signals,
        using random sampling from pre-signal timepoints accross 
        replicates and events.

        Note
        ----
        This requires that events have already been extacted!

        Parameters
        ----------
        size : int or float
            The number of random samples to draw. If `None` are provided (default)
            the entire available pre-signal data is used. If an `integer` is provided
            then the final baseline data contains exactly the given number of datapoints.
            Alternatively, a `float` `0 &lt; size &lt;= 1` may be provided to specify a fraction
            of data to sample from. E.g. `size = 0.2` would incorporate 20% of the available
            datapoints into the baseline.
        
        Returns
        -------
        baseline : np.ndarray
            An np.ndarray of the randomly drawn samples.
        &#34;&#34;&#34;
        start_sec, stop_sec = self._start_sec, self._stop_sec

        # first get the time period before t=0, beginning at the starting time...
        if isinstance( self._data, list ):
            random_samples = [ self._extract_window( start_sec, 0, e ) for e in self._extracted_events ]
        elif isinstance( self._data, np.ndarray ):
            random_samples = [ self._extract_window( start_sec, 0, self._extracted_events ) ]        
        elif self._data is None:
            raise Exception( f&#34;No events data has been extracted yet! Make sure to run extract() before computing a baseline.&#34; )

        # collapse the repeats into a single dataset
        random_samples = [ np.reshape( i, i.size ) for i in random_samples ] 

        # now if there is a provided size we subsample
        if size is not None: 
            if size &lt;= 1:
                random_samples = [ np.random.choice( i, size = size * i.size ) for i in random_samples ]
            elif size &gt; 1:
                random_samples = [ np.random.choice( i, size = size ) for i in random_samples ]
            else:
                raise ValueError( f&#34;size needs to be a fraction in [0,1] or an integer &gt; 1 (got size = {size})&#34; )

        self._baseline = random_samples

        # Alright, we currently have the entire sets of pre-timeframes for the baseline and we
        # will use them as they are completely to use for the baseline comparison. 
        # With the code below we compare a sub-sampled versions thereof. Long story short,
        # it works also pretty well with sub-sampled versions as well...
        # import statsmodels.api as sm
        # from matplotlib import colors

        # fig, ax = plt.subplots( 2,3 ) 
        # for r in random_samples:
        #     ax[0,0].plot( r )
        #     r1 = r.reshape( r.size )
        #     ax[0,1].hist( r1, bins = 50 )

        #     sm.qqplot( r1, ax = ax[0,2], alpha = 0.3, line = &#34;s&#34;, color = list(colors.cnames.values())[ int(np.random.randint(low = 0, high = 10, size = 1))]  )
        # random_samples = [ np.random.choice( r.reshape(r.size), size = size, replace = False ) for r in random_samples ]
        
        # for r in random_samples:
        #     ax[1,0].plot( r )
        #     r1 = np.reshape( r, r.size )
        #     ax[1,1].hist( r1, bins = 50 )
            
        #     sm.qqplot( r1, ax = ax[1,2], alpha = 0.3, line = &#34;s&#34;, color =  list(colors.cnames.values())[ int(np.random.randint(low = 0, high = 10, size = 1))] )
        # # ax[1].hist( np.reshape( random_samples, random_samples.size)  )
        # plt.tight_layout()
        # plt.show()


    def pvalues( self, event1 : int, event2 : int = None ):
        &#34;&#34;&#34;
        Gets the p-value np.ndarray for each signal timepoint from a comparison of 
        either two separate event types or one event with its baseline. 

        Parameters
        ----------
        event1 : int
            The numeric event identifier of the (first) signal to get.
            If `None` is provided, the entire dictionary of pvalues is returned.

        event2 : int
            The numeric event identifier of the (second) signal from the comparison to get.
            If `None` is provided then the first signals comparison to it&#39;s baseline will be 
            returned (if baseline comparison was performed).
        
        Returns
        -------
        pvalues : np.ndarray or dict
            An np.ndarray of p-values from a given comparison.
        &#34;&#34;&#34;

        if event1 is None: 
            return self._pvalues

        if event2 is None:
            key = (event1, event1)
        else: 
            key = (event1, event2)
        pvalues = self._pvalues.get( key, None )
        return pvalues 

    @property
    def events( self ):
        &#34;&#34;&#34;
        Returns 
        -------
        list
            A list of all different event types from from the loaded metadata.
        &#34;&#34;&#34;
        return list( self._events.keys() )

    @property
    def timeframe( self ):
        &#34;&#34;&#34;
        Returns
        -------
        tuple   
            The used timeframe for event data extraction.
            This consists of the pre-trigger and post-trigger
            time offsets in seconds.
        &#34;&#34;&#34;
        return ( self._start_sec, self._stop_sec )



    def summary(self,
                x_scale:float,
                y_scale:float,
                significance_level:float = 0.05,
                output:str = None,
                **kwargs ) -&gt; None:
        &#34;&#34;&#34;
        Performs pair-wise T-Tests to compare extracted event data 
        (automatically extracts data for all events if no events were extracted yet). 
        Results are summarised in a figure. Individual signals are plotted
        on the diagonal by their mean signal accross replicates with indicated SEM.
        On non-diagonal plots pair-wise comparisons between two signals (one &#34;horizontal&#34;
        and one &#34;vertical&#34; ) are shown. Regions of significant differences are shaded.

        Parameters
        ----------

        x_scale : float
            A scaling factor to adjust the data&#39;s x-value range. 
            E.g. `x_scale = 1000` to adjust the time-scale to milliseconds.
        
        y_scale : float
            A scaling factor for the data&#39;s y-value range.
            E.g. `y_scale = 1000` to adjust the signal-scale to millivolts.

        significance_level : float
            The threshold for accepting a signal difference as significant.
            Default is `0.05`.
        
        output : str
            The output filename to save the summary figure into.

        **kwargs
            Any additional keyword arguments to pass to `EEGData.extract` in case
            no event data has been extracted yet.
        &#34;&#34;&#34;

        # extract the event data if not yet done already
        start_sec = kwargs.pop( &#34;start_sec&#34;, self._start_sec )
        stop_sec = kwargs.pop( &#34;stop_sec&#34;, self._stop_sec )
        if self._data is None: 

            self.extract( start_sec = start_sec, stop_sec = stop_sec, **kwargs )
            self.baseline() 

        data = list( self._data ) 
        signals = list(self._events.keys())
        n = len(data)

        # generate a new figure
        figsize = kwargs.pop( &#34;figsize&#34;, ( 3*n,2*n ) )
        fig, ax = plt.subplots(n,n, figsize = figsize )

        # setup a baseline reference, either with the computed
        # baselines or None ...
        baseline = self._baseline if self._baseline is not None else [ None for i in range(n) ]
    
        # now first plot the individual signals
        # on their own on diagonal plots
        for i in range(n):

            # only the last subplot should make a legend
            make_legend = i == n-1 
            p = plot_signal(
                    data[i], 
                    self.sampling_frequency, 
                    start_sec, stop_sec, 
                    x_scale, y_scale,
                    baseline = baseline[i],
                    make_legend = make_legend,
                    significance_level = significance_level,
                    ax = ax[i,i] )
                
            ax[i,i].set_title(f&#34;Signal {signals[i]}&#34;)

            # if we got a baseline to compare to we also want to 
            # store the resulting p-values
            if p is not None: 
                self._pvalues[ (i,i) ] = p 

            # hide all &#34;left-over&#34; subplots from the layout
            # i.e. hide the upper-right half of the figure...
            for a in ax[ i, i+1: ]:
                a.axis(&#34;off&#34;)

        # now make pair-wise comparisons between two signals
        # plotting the results on the lower-left half of the 
        # figure...
        for i,j in [(i,j) for i in range(n) for j in range(i)]:

            # only the last plot shall make a legend
            make_legend = i == n-1 and j == i-1 

            p = difference_plot( 
                                data[i], 
                                data[j], 
                                self.sampling_frequency, 
                                start_sec, stop_sec, 
                                significance_level, 
                                x_scale, y_scale,
                                make_legend = make_legend,
                                ax = ax[i,j]
                            )
            ax[i,j].set_title(f&#34;Signals: {signals[j]} vs {signals[i]}&#34;)

            # we also want to store the resulting p-values of the 
            # signal comparison
            self._pvalues[ ( signals[j],signals[i] ) ] = p

        fig.tight_layout()
        
        if output is None:
            plt.show()
            return fig
        plt.savefig(output, bbox_inches = &#34;tight&#34; )


    def _extract_window(self, start_sec, stop_sec, event_type):
        &#34;&#34;&#34;
        Extracts a set of time-frame windows from the data 
        and returns them as a numpy ndarray.
        &#34;&#34;&#34;

        # first adjust the start and end to 
        # match the sampling frequency
        start_frame, stop_frame = self._adjust_timesteps(start_sec, stop_sec)

        # next generate a set of slices for the EEG data around the timepoints for
        # the events
        firing_slices = [
                            slice( event[0]+start_frame, event[0]+stop_frame ) 
                            for event in self._events_data 
                            if event[1] == event_type
                    ]

        # now get the actual data of the event
        data = [ self.signal[ slice ] for slice in firing_slices ]
        data = np.array( data )
        return data

    def _adjust_timesteps(self, start_sec, stop_sec):
        &#34;&#34;&#34;
        Adjusts time steps / time points with the used recording frequency,
        to match the indices within the data.
        &#34;&#34;&#34;
        start_frame = int( start_sec * self.sampling_frequency )
        stop_frame = int( stop_sec * self.sampling_frequency )
        return start_frame,stop_frame

    def _set_n_events(self) -&gt; None:
        &#34;&#34;&#34;
        Sets up a dictionary of the different event types
        found in the events data.
        &#34;&#34;&#34;

        event_types = {event[1] for event in self._events_data}
        self._events = {event_type: len([event for event in self._events_data if event[1] == event_type]) for event_type in event_types}            

    def _check_sanity(self, signal_path, event_path, sampling_frequency):
        &#34;&#34;&#34;
        Checks if valid data inputs were provided
        &#34;&#34;&#34;

        # check if input files exist
        if not os.path.isfile(signal_path):
            raise FileNotFoundError( f&#34;The signal datafile could not be found at &#39;{signal_path}&#39;!&#34; )
        
        if not os.path.isfile(event_path):
            raise FileNotFoundError( f&#34;The event datafile could not be found at &#39;{event_path}!&#34; )
        
        # check if the datafiles conform to suppored filetypes
        fname = os.path.basename(signal_path)
        if not any( [ fname.endswith(suffix) for suffix in supported_filetypes ] ):
            suffix = fname.split(&#34;.&#34;)[-1]
            raise TypeError( f&#34;The signal datafile could not be interpreted (&#39;.{suffix}&#39;), only {supported_filetypes} files are supported!&#34; )

        fname = os.path.basename(event_path)
        if not any( [ fname.endswith(suffix) for suffix in supported_filetypes ] ):
            suffix = fname.split(&#34;.&#34;)[-1]
            raise TypeError( f&#34;The event datafile could not be interpreted (&#39;.{suffix}&#39;), only {supported_filetypes} files are supported!&#34; )
        
        # check if the frequency is a positive number
        if not sampling_frequency &gt; 0:
            raise ValueError( f&#34;Sampling frequency {sampling_frequency} must be a positive value&#34; )

    def _read_npy( self, filepath ) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Reads data from npy files
        &#34;&#34;&#34;
        data = np.load(filepath)
        return data 

    def _read_datafile( self, filepath) -&gt; np.ndarray: 
        &#34;&#34;&#34;
        Reads data from tsv, csv, and txt files
        &#34;&#34;&#34;

        # first get the filetype 
        suffix = self._filesuffix(filepath)

        # now get the corresponding delimiter
        delimiters = {
                        &#34;csv&#34; : self._csv_delimiter( filepath ),
                        &#34;tsv&#34; : &#34;\t&#34;,
                        &#34;txt&#34; : &#34; &#34;
                    }
        delimiter = delimiters[ suffix ]
        
        # now read the file
        data = pd.read_csv( filepath, header = None, sep = delimiter )

        # convert to numpy ndarray
        data = data.to_numpy()
        data = np.squeeze( data )
        return data 

    def _filesuffix(self, filepath):
        &#34;&#34;&#34;
        Returns the suffix from a filepath
        &#34;&#34;&#34;
        suffix = os.path.basename( filepath )
        suffix = suffix.split(&#34;.&#34;)[-1]
        return suffix

    def _csv_delimiter(self, filepath):
        &#34;&#34;&#34;
        Checks if a csv file is , or ; delimited and returns the 
        correct delmiter to use...
        &#34;&#34;&#34;
        # open the file and read 
        with open( filepath, &#34;r&#34; ) as f:
            content = f.read()

        # check if a semicolon is present
        # if so, we delimit at ; 
        has_semicolon = &#34;;&#34; in content
        delimiter = &#34;;&#34; if has_semicolon else &#34;,&#34;

        return delimiter</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="EEGToolkit.auxiliary.auxiliary.stEEGData" href="../auxiliary/auxiliary.html#EEGToolkit.auxiliary.auxiliary.stEEGData">stEEGData</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.events"><code class="name">var <span class="ident">events</span></code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<p>list
A list of all different event types from from the loaded metadata.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def events( self ):
    &#34;&#34;&#34;
    Returns 
    -------
    list
        A list of all different event types from from the loaded metadata.
    &#34;&#34;&#34;
    return list( self._events.keys() )</code></pre>
</details>
</dd>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.timeframe"><code class="name">var <span class="ident">timeframe</span></code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple
</code></dt>
<dd>The used timeframe for event data extraction.
This consists of the pre-trigger and post-trigger
time offsets in seconds.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def timeframe( self ):
    &#34;&#34;&#34;
    Returns
    -------
    tuple   
        The used timeframe for event data extraction.
        This consists of the pre-trigger and post-trigger
        time offsets in seconds.
    &#34;&#34;&#34;
    return ( self._start_sec, self._stop_sec )</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.baseline"><code class="name flex">
<span>def <span class="ident">baseline</span></span>(<span>self, size:Â intÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a baseline distribution for EEG Signals,
using random sampling from pre-signal timepoints accross
replicates and events.</p>
<h2 id="note">Note</h2>
<p>This requires that events have already been extacted!</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>The number of random samples to draw. If <code>None</code> are provided (default)
the entire available pre-signal data is used. If an <code>integer</code> is provided
then the final baseline data contains exactly the given number of datapoints.
Alternatively, a <code>float</code> <code>0 &lt; size &lt;= 1</code> may be provided to specify a fraction
of data to sample from. E.g. <code>size = 0.2</code> would incorporate 20% of the available
datapoints into the baseline.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>baseline</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An np.ndarray of the randomly drawn samples.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def baseline( self, size : int or float = None ):
    &#34;&#34;&#34;
    Generates a baseline distribution for EEG Signals,
    using random sampling from pre-signal timepoints accross 
    replicates and events.

    Note
    ----
    This requires that events have already been extacted!

    Parameters
    ----------
    size : int or float
        The number of random samples to draw. If `None` are provided (default)
        the entire available pre-signal data is used. If an `integer` is provided
        then the final baseline data contains exactly the given number of datapoints.
        Alternatively, a `float` `0 &lt; size &lt;= 1` may be provided to specify a fraction
        of data to sample from. E.g. `size = 0.2` would incorporate 20% of the available
        datapoints into the baseline.
    
    Returns
    -------
    baseline : np.ndarray
        An np.ndarray of the randomly drawn samples.
    &#34;&#34;&#34;
    start_sec, stop_sec = self._start_sec, self._stop_sec

    # first get the time period before t=0, beginning at the starting time...
    if isinstance( self._data, list ):
        random_samples = [ self._extract_window( start_sec, 0, e ) for e in self._extracted_events ]
    elif isinstance( self._data, np.ndarray ):
        random_samples = [ self._extract_window( start_sec, 0, self._extracted_events ) ]        
    elif self._data is None:
        raise Exception( f&#34;No events data has been extracted yet! Make sure to run extract() before computing a baseline.&#34; )

    # collapse the repeats into a single dataset
    random_samples = [ np.reshape( i, i.size ) for i in random_samples ] 

    # now if there is a provided size we subsample
    if size is not None: 
        if size &lt;= 1:
            random_samples = [ np.random.choice( i, size = size * i.size ) for i in random_samples ]
        elif size &gt; 1:
            random_samples = [ np.random.choice( i, size = size ) for i in random_samples ]
        else:
            raise ValueError( f&#34;size needs to be a fraction in [0,1] or an integer &gt; 1 (got size = {size})&#34; )

    self._baseline = random_samples

    # Alright, we currently have the entire sets of pre-timeframes for the baseline and we
    # will use them as they are completely to use for the baseline comparison. 
    # With the code below we compare a sub-sampled versions thereof. Long story short,
    # it works also pretty well with sub-sampled versions as well...
    # import statsmodels.api as sm
    # from matplotlib import colors

    # fig, ax = plt.subplots( 2,3 ) 
    # for r in random_samples:
    #     ax[0,0].plot( r )
    #     r1 = r.reshape( r.size )
    #     ax[0,1].hist( r1, bins = 50 )

    #     sm.qqplot( r1, ax = ax[0,2], alpha = 0.3, line = &#34;s&#34;, color = list(colors.cnames.values())[ int(np.random.randint(low = 0, high = 10, size = 1))]  )
    # random_samples = [ np.random.choice( r.reshape(r.size), size = size, replace = False ) for r in random_samples ]
    
    # for r in random_samples:
    #     ax[1,0].plot( r )
    #     r1 = np.reshape( r, r.size )
    #     ax[1,1].hist( r1, bins = 50 )
        
    #     sm.qqplot( r1, ax = ax[1,2], alpha = 0.3, line = &#34;s&#34;, color =  list(colors.cnames.values())[ int(np.random.randint(low = 0, high = 10, size = 1))] )
    # # ax[1].hist( np.reshape( random_samples, random_samples.size)  )
    # plt.tight_layout()
    # plt.show()</code></pre>
</details>
</dd>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.extract"><code class="name flex">
<span>def <span class="ident">extract</span></span>(<span>self, start_sec:Â float, stop_sec:Â float, event_type:Â intÂ =Â None, **kwargs) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts data for a specific (set of) event(s) from the loaded data.
And returns the data as numpy ndarrays (or a list thereof, in case of
multiple events).</p>
<h2 id="note">Note</h2>
<p>This method is automatically called by <code>EGGData.summary</code> so it is not necessary
to manually extract data, unless only a specific subset of event types should
be extracted!</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>start_sec</code></strong> :&ensp;<code>float</code></dt>
<dd>The timepoint relative to the provided
events data in seconds at which to begin extraction.
E.g. <code>-0.05</code> would correspond to <code>0.05 seconds</code> before
the actual onset of the recorded event.</dd>
<dt><strong><code>stop_sec</code></strong> :&ensp;<code>float</code></dt>
<dd>The timepoint relative to the provided
events data in seconds at which to end extraction.
E.g. <code>0.75</code> would correspond to <code>0.75 seconds</code> after
the actual onset of the recorded event.</dd>
<dt><strong><code>event_type</code></strong> :&ensp;<code>int</code> or <code>tuple</code> or <code>list</code> or <code>np.ndarray</code></dt>
<dd>Either a single event type or an iterable of multiple event types.
If <code>event_type = None</code> (default) data for <strong>all</strong> event types will be extracted!</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>extracted_data</code></strong> :&ensp;<code>np.ndarray</code> or <code>list</code></dt>
<dd>The data of the provided events as an ndarray or a
list of ndarrays in the same order as the provided event-type labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract(self,
            start_sec:float,
            stop_sec:float,
            event_type : ( int or tuple or list or np.ndarray ) = None, 
            **kwargs ) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Extracts data for a specific (set of) event(s) from the loaded data. 
    And returns the data as numpy ndarrays (or a list thereof, in case of 
    multiple events).

    Note
    ----
    This method is automatically called by `EGGData.summary` so it is not necessary
    to manually extract data, unless only a specific subset of event types should
    be extracted!

    Parameters
    ----------
    start_sec : float
        The timepoint relative to the provided 
        events data in seconds at which to begin extraction. 
        E.g. `-0.05` would correspond to `0.05 seconds` before
        the actual onset of the recorded event.

    stop_sec : float
        The timepoint relative to the provided 
        events data in seconds at which to end extraction. 
        E.g. `0.75` would correspond to `0.75 seconds` after
        the actual onset of the recorded event.
    
    event_type : int or tuple or list or np.ndarray
        Either a single event type or an iterable of multiple event types.
        If `event_type = None` (default) data for **all** event types will be extracted!

    Returns
    -------
    extracted_data : np.ndarray or list
        The data of the provided events as an ndarray or a 
        list of ndarrays in the same order as the provided event-type labels.
    &#34;&#34;&#34;

    # check if we should extract the data for all events
    if event_type is None:

        # get all events
        events_to_extract = self._events.keys()

        # extract each type from the loaded data
        data = [ 
                    self.extract(start_sec, stop_sec, etype) 
                    for etype in events_to_extract 
            ]

        self._data = data
        self._extracted_events = events_to_extract
        return data

    # check if there is a provided subset of events to extract
    if isinstance(event_type, (tuple, np.ndarray, list)):

        events_to_extract = event_type

        # extract provided type from the loaded data
        data = [ 
                    self.extract(start_sec, stop_sec, etype) 
                    for etype in events_to_extract 
            ]

        self._data = data
        self._extracted_events = events_to_extract
        return data

    # now the part for extracting only a 
    # single event type data
    data = self._extract_window(start_sec, stop_sec, event_type)
    self._data = data

    self._extracted_events = event_type

    # store start and stop sec values
    # for later use in summary()
    self._start_sec = start_sec
    self._stop_sec = stop_sec

    return data</code></pre>
</details>
</dd>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.pvalues"><code class="name flex">
<span>def <span class="ident">pvalues</span></span>(<span>self, event1:Â int, event2:Â intÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the p-value np.ndarray for each signal timepoint from a comparison of
either two separate event types or one event with its baseline. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event1</code></strong> :&ensp;<code>int</code></dt>
<dd>The numeric event identifier of the (first) signal to get.
If <code>None</code> is provided, the entire dictionary of pvalues is returned.</dd>
<dt><strong><code>event2</code></strong> :&ensp;<code>int</code></dt>
<dd>The numeric event identifier of the (second) signal from the comparison to get.
If <code>None</code> is provided then the first signals comparison to it's baseline will be
returned (if baseline comparison was performed).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pvalues</code></strong> :&ensp;<code>np.ndarray</code> or <code>dict</code></dt>
<dd>An np.ndarray of p-values from a given comparison.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pvalues( self, event1 : int, event2 : int = None ):
    &#34;&#34;&#34;
    Gets the p-value np.ndarray for each signal timepoint from a comparison of 
    either two separate event types or one event with its baseline. 

    Parameters
    ----------
    event1 : int
        The numeric event identifier of the (first) signal to get.
        If `None` is provided, the entire dictionary of pvalues is returned.

    event2 : int
        The numeric event identifier of the (second) signal from the comparison to get.
        If `None` is provided then the first signals comparison to it&#39;s baseline will be 
        returned (if baseline comparison was performed).
    
    Returns
    -------
    pvalues : np.ndarray or dict
        An np.ndarray of p-values from a given comparison.
    &#34;&#34;&#34;

    if event1 is None: 
        return self._pvalues

    if event2 is None:
        key = (event1, event1)
    else: 
        key = (event1, event2)
    pvalues = self._pvalues.get( key, None )
    return pvalues </code></pre>
</details>
</dd>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, signal_path:Â strÂ =Â None, event_path:Â strÂ =Â None) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Read the provided data files and stores the
data into numpy ndarrays.</p>
<h2 id="note">Note</h2>
<p>This method is automatically called at initiation. However, new data
can be loaded using this method manually.</p>
<h2 id="input-datafiles">Input Datafiles</h2>
<p>The EEG signal datafile must be a 1D array of values.
The events datafile must be a 2D array of timepoints at which an event occurs,
as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
datafiles must <strong>not</strong> contain any headers!</p>
<p>Supported file types are:
- <code>npy</code>
- <code>txt</code>
( space-separated for events datafiles )
- <code>tsv</code>
- <code>csv</code>
(both <code>,</code> and <code>;</code> separated )
</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>signal_path</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a valid datafile containing EEG signal data.</dd>
<dt><strong><code>event_path</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a valid datafile containing corresponding
event information for the signal datafile.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read( self, signal_path : str = None , event_path : str = None ) -&gt; None: 
    &#34;&#34;&#34;
    Read the provided data files and stores the
    data into numpy ndarrays.

    Note
    ----
    This method is automatically called at initiation. However, new data
    can be loaded using this method manually.

    Input Datafiles
    --------------
    The EEG signal datafile must be a 1D array of values. 
    The events datafile must be a 2D array of timepoints at which an event occurs,
    as well as a categorical (numerically encoded) label of the kind of event that occured. Note, that the
    datafiles must **not** contain any headers!

    Supported file types are:
    - `npy`
    - `txt`     ( space-separated for events datafiles )
    - `tsv`
    - `csv`     (both `,` and `;` separated )   

    Parameters
    ----------
    signal_path : str
        A filepath to a valid datafile containing EEG signal data.
    
    event_path : str
        A filepath to a valid datafile containing corresponding 
        event information for the signal datafile.

    &#34;&#34;&#34;
    
    # first read the signal data file
    if signal_path is not None:
        suffix = self._filesuffix( signal_path )
        if suffix == &#34;npy&#34;: 
            signal = self._read_npy( signal_path )
        else: 
            signal = self._read_datafile( signal_path )

        # now save
        self.signal = signal

    # now the same for the events data file 
    if event_path is not None: 
        suffix = self._filesuffix( event_path )
        if suffix == &#34;npy&#34;: 
            events = self._read_npy( event_path )
        else: 
            events = self._read_datafile( event_path )

        # now save
        self._events_data = events</code></pre>
</details>
</dd>
<dt id="EEGToolkit.EEGData.EEGData.EEGData.summary"><code class="name flex">
<span>def <span class="ident">summary</span></span>(<span>self, x_scale:Â float, y_scale:Â float, significance_level:Â floatÂ =Â 0.05, output:Â strÂ =Â None, **kwargs) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Performs pair-wise T-Tests to compare extracted event data
(automatically extracts data for all events if no events were extracted yet).
Results are summarised in a figure. Individual signals are plotted
on the diagonal by their mean signal accross replicates with indicated SEM.
On non-diagonal plots pair-wise comparisons between two signals (one "horizontal"
and one "vertical" ) are shown. Regions of significant differences are shaded.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_scale</code></strong> :&ensp;<code>float</code></dt>
<dd>A scaling factor to adjust the data's x-value range.
E.g. <code>x_scale = 1000</code> to adjust the time-scale to milliseconds.</dd>
<dt><strong><code>y_scale</code></strong> :&ensp;<code>float</code></dt>
<dd>A scaling factor for the data's y-value range.
E.g. <code>y_scale = 1000</code> to adjust the signal-scale to millivolts.</dd>
<dt><strong><code>significance_level</code></strong> :&ensp;<code>float</code></dt>
<dd>The threshold for accepting a signal difference as significant.
Default is <code>0.05</code>.</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code></dt>
<dd>The output filename to save the summary figure into.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword arguments to pass to <code><a title="EEGToolkit.EEGData.EEGData.EEGData.extract" href="#EEGToolkit.EEGData.EEGData.EEGData.extract">EEGData.extract()</a></code> in case
no event data has been extracted yet.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summary(self,
            x_scale:float,
            y_scale:float,
            significance_level:float = 0.05,
            output:str = None,
            **kwargs ) -&gt; None:
    &#34;&#34;&#34;
    Performs pair-wise T-Tests to compare extracted event data 
    (automatically extracts data for all events if no events were extracted yet). 
    Results are summarised in a figure. Individual signals are plotted
    on the diagonal by their mean signal accross replicates with indicated SEM.
    On non-diagonal plots pair-wise comparisons between two signals (one &#34;horizontal&#34;
    and one &#34;vertical&#34; ) are shown. Regions of significant differences are shaded.

    Parameters
    ----------

    x_scale : float
        A scaling factor to adjust the data&#39;s x-value range. 
        E.g. `x_scale = 1000` to adjust the time-scale to milliseconds.
    
    y_scale : float
        A scaling factor for the data&#39;s y-value range.
        E.g. `y_scale = 1000` to adjust the signal-scale to millivolts.

    significance_level : float
        The threshold for accepting a signal difference as significant.
        Default is `0.05`.
    
    output : str
        The output filename to save the summary figure into.

    **kwargs
        Any additional keyword arguments to pass to `EEGData.extract` in case
        no event data has been extracted yet.
    &#34;&#34;&#34;

    # extract the event data if not yet done already
    start_sec = kwargs.pop( &#34;start_sec&#34;, self._start_sec )
    stop_sec = kwargs.pop( &#34;stop_sec&#34;, self._stop_sec )
    if self._data is None: 

        self.extract( start_sec = start_sec, stop_sec = stop_sec, **kwargs )
        self.baseline() 

    data = list( self._data ) 
    signals = list(self._events.keys())
    n = len(data)

    # generate a new figure
    figsize = kwargs.pop( &#34;figsize&#34;, ( 3*n,2*n ) )
    fig, ax = plt.subplots(n,n, figsize = figsize )

    # setup a baseline reference, either with the computed
    # baselines or None ...
    baseline = self._baseline if self._baseline is not None else [ None for i in range(n) ]

    # now first plot the individual signals
    # on their own on diagonal plots
    for i in range(n):

        # only the last subplot should make a legend
        make_legend = i == n-1 
        p = plot_signal(
                data[i], 
                self.sampling_frequency, 
                start_sec, stop_sec, 
                x_scale, y_scale,
                baseline = baseline[i],
                make_legend = make_legend,
                significance_level = significance_level,
                ax = ax[i,i] )
            
        ax[i,i].set_title(f&#34;Signal {signals[i]}&#34;)

        # if we got a baseline to compare to we also want to 
        # store the resulting p-values
        if p is not None: 
            self._pvalues[ (i,i) ] = p 

        # hide all &#34;left-over&#34; subplots from the layout
        # i.e. hide the upper-right half of the figure...
        for a in ax[ i, i+1: ]:
            a.axis(&#34;off&#34;)

    # now make pair-wise comparisons between two signals
    # plotting the results on the lower-left half of the 
    # figure...
    for i,j in [(i,j) for i in range(n) for j in range(i)]:

        # only the last plot shall make a legend
        make_legend = i == n-1 and j == i-1 

        p = difference_plot( 
                            data[i], 
                            data[j], 
                            self.sampling_frequency, 
                            start_sec, stop_sec, 
                            significance_level, 
                            x_scale, y_scale,
                            make_legend = make_legend,
                            ax = ax[i,j]
                        )
        ax[i,j].set_title(f&#34;Signals: {signals[j]} vs {signals[i]}&#34;)

        # we also want to store the resulting p-values of the 
        # signal comparison
        self._pvalues[ ( signals[j],signals[i] ) ] = p

    fig.tight_layout()
    
    if output is None:
        plt.show()
        return fig
    plt.savefig(output, bbox_inches = &#34;tight&#34; )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="EEGToolkit.EEGData" href="index.html">EEGToolkit.EEGData</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="EEGToolkit.EEGData.EEGData.main" href="#EEGToolkit.EEGData.EEGData.main">main</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="EEGToolkit.EEGData.EEGData.EEGData" href="#EEGToolkit.EEGData.EEGData.EEGData">EEGData</a></code></h4>
<ul class="two-column">
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.baseline" href="#EEGToolkit.EEGData.EEGData.EEGData.baseline">baseline</a></code></li>
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.events" href="#EEGToolkit.EEGData.EEGData.EEGData.events">events</a></code></li>
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.extract" href="#EEGToolkit.EEGData.EEGData.EEGData.extract">extract</a></code></li>
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.pvalues" href="#EEGToolkit.EEGData.EEGData.EEGData.pvalues">pvalues</a></code></li>
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.read" href="#EEGToolkit.EEGData.EEGData.EEGData.read">read</a></code></li>
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.summary" href="#EEGToolkit.EEGData.EEGData.EEGData.summary">summary</a></code></li>
<li><code><a title="EEGToolkit.EEGData.EEGData.EEGData.timeframe" href="#EEGToolkit.EEGData.EEGData.EEGData.timeframe">timeframe</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>